#!/usr/bin/env python

"""
    Copyright (C) 2015  Ivan Gregor

    This program is free software: you can redistribute it and/or modify
    it under the terms of the GNU General Public License as published by
    the Free Software Foundation, either version 3 of the License, or
    (at your option) any later version.

    This program is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
    GNU General Public License for more details.

    You should have received a copy of the GNU General Public License
    along with this program.  If not, see <http://www.gnu.org/licenses/>.

    The master script of the Snowball gene assembler. Module version 1.2
"""

import os
import sys
import platform
import tempfile
import shutil
import argparse
import multiprocessing as mp

from algbioi.com import fq
from algbioi.com import parallel
from algbioi.hsim import comh
from algbioi.haplo import hmain
from algbioi.haplo import hio


def mainSnowball(fq1Path, fq2Path, profileHmmFile, insertSize, readLen=None, outFile=None, outFormat='fna',
                 workingDir=None, hmmsearchPath=None, pfamMinScore=None, pOverlap=None, overlapLen=None,
                 outAnnot=False, cleanUp=False, processors=mp.cpu_count()):
    """
        Main function, the interface of the Snowball gene assembler.

        @param fq1Path: FASTQ 1 file path (containing first ends of Illumina paired-end reads)
        @param fq2Path: FASTQ 2 file path (containing second ends)
        @param profileHmmFile: profile HMMs file, containing models generated by the HMMER 3 software
        @param insertSize: mean insert size used for the library preparation (i.e. read generation)
        @param readLen: read length (if None, it will be derived from the FASTQ file)
        @param outFile: output file (if None, it will be derived from the FASTQ 1 file)
        @param outFormat: output file format 'fna' or 'fq'
        @param workingDir: temporary files will be stored here (if None, a temporary directory will be created/deleted)
        @param hmmsearchPath: path to the HMMER hmmsearch command (if None, it will take version that is in the PATH)
        @param pfamMinScore: minimum score for the hmmsearch (if None, use default)
        @param pOverlap: minimum overlap probability for the Snowball algorithm
        @param overlapLen: minimum overlap length for the Snowball algorithm
        @param outAnnot: if true, additional annotation will be stored along with the resulting contigs
        @param cleanUp: if true, delete temporary files at the end
        @param processors: Number of processors (default: use all processors available)

        @type fq1Path: str
        @type fq2Path: str
        @type profileHmmFile: str
        @type insertSize: int
        @type readLen: str
        @type outFile: str
        @type outFormat: str
        @type workingDir: str
        @type hmmsearchPath: str
        @type pfamMinScore: int
        @type pOverlap: float
        @type overlapLen: float
        @type outAnnot: bool
        @type cleanUp: bool
        @type processors: int
    """
    assert os.name == 'posix', 'Snowball runs only on "posix" systems, your system is: %s' % os.name

    # checking input parameters
    assert os.path.isfile(fq1Path), 'File does not exist: %s' % fq1Path
    assert os.path.isfile(fq2Path), 'File does not exist: %s' % fq2Path

    # derive the read length
    if readLen is None:
        for name, dna, p, qs in fq.ReadFqGen(fq1Path):
            readLen = len(dna)
            assert readLen == len(qs), 'File corrupted %s' % fq1Path
            break
    assert readLen is not None, 'Cannot derive read length from %s' % fq1Path

    assert readLen <= insertSize < 2 * readLen, 'Invalid read length (%s) and insert size (%s) combination' \
                                                % (readLen, insertSize)

    assert os.path.isfile(profileHmmFile), 'File does not exist: %s' % profileHmmFile

    outFormat = outFormat.strip()
    assert outFormat == 'fna' or outFormat == 'fq', 'Invalid output format: %s' % outFormat

    # checking the output file
    if outFile is None:
        c = 0
        while True:
            outFile = fq1Path + '_%s.%s.gz' % (c, outFormat)
            if not os.path.isfile(outFile):
                break
            c += 1
    else:
        outFileDir = os.path.dirname(outFile)
        assert os.path.basename(outFile) != '', 'Output file name is empty'
        assert outFileDir == '' or os.path.isdir(outFileDir), 'Invalid output directory: %s' % outFileDir
        outFile = outFile.strip()
        if not outFile.endswith('.gz'):
            outFile += '.gz'
            print('The name of the output file was modified to:\n\t%s' % outFile)

    # Looking for the hmmsearch binaries
    if hmmsearchPath is None:
        hmmsearchPath = os.popen("which hmmsearch").read().strip()
        if hmmsearchPath != '':
            print('This hmmsearch binary will be used:\n\t%s' % hmmsearchPath)

    assert os.path.isfile(hmmsearchPath), 'Path for (hmmsearch) is invalid: %s' % hmmsearchPath

    # creates a temporary working directory
    if workingDir is None:
        workingDir = tempfile.mkdtemp(prefix='snowball_')
        assert os.path.isdir(workingDir), 'Cannot create temporary working directory (%s)' % workingDir
        cleenUpTmpWorkingDir = True
        print('Using temporary directory:\n\t%s' % workingDir)
    else:
        cleenUpTmpWorkingDir = False

    assert os.path.isdir(workingDir), 'Working directory does not exist:\n\t%s' % workingDir
    assert not os.listdir(workingDir), 'Working directory must be empty:\n\t%s' % workingDir

    # set the number of processor cores to be used
    comh.MAX_PROC = max(1, min(processors, mp.cpu_count()))

    # set assembly parameters or use defaults
    if pfamMinScore is not None:
        comh.SAMPLES_PFAM_EVAN_MIN_SCORE = pfamMinScore

    if pOverlap is not None:
        comh.ASSEMBLY_POVERLAP = (pOverlap,)

    if overlapLen is not None:
        comh.ASSEMBLY_OVERLAP_LEN = (overlapLen,)

    # creates a temporary directory for the sample strains
    strainsDir = os.path.join(workingDir, 'strains')
    if not os.path.isdir(strainsDir):
        os.mkdir(strainsDir)
    assert os.path.isdir(strainsDir), 'Cannot create temporary directory:\n\t%s' % strainsDir

    os.symlink(fq1Path, os.path.join(strainsDir, '0_pair1.fq.gz'))
    os.symlink(fq2Path, os.path.join(strainsDir, '0_pair2.fq.gz'))

    # Start of the algorithm
    print('Running on: %s (%s)' % (' '.join(platform.dist()), sys.platform))
    print('Using %s processors' % comh.MAX_PROC)
    print('Settings:\n\tRead length: %s\n\tInsert size: %s\n\tMin. overlap probability: %s\n\tMin. overlap length: %s'
          '\n\tMin. HMM score: %s'

          % (readLen, insertSize, comh.ASSEMBLY_POVERLAP[0], comh.ASSEMBLY_OVERLAP_LEN[0],
             comh.SAMPLES_PFAM_EVAN_MIN_SCORE))

    # file with joined consensus reads
    fqJoinPath = os.path.join(strainsDir, '0_join.fq.gz')

    # join paired-end reads
    if True:  # to skip this step, set to False (e.g. resume processing after OS/HW failure)
        print('Joining paired-end reads into consensus reads, loading reads from:\n\t%s\n\t%s' % (fq1Path, fq2Path))

        r = fq.joinPairEnd([(fq1Path, fq2Path, fqJoinPath, readLen, insertSize, None, 60)],
                           minOverlap=comh.SAMPLES_PAIRED_END_JOIN_MIN_OVERLAP,
                           minOverlapIdentity=comh.SAMPLES_PAIRED_END_JOIN_MIN_OVERLAP_IDENTITY,
                           maxCpu=comh.MAX_PROC)
        print("Filtered out: %s %% reads" % r)

    # Translate consensus reads into protein sequences, run hmmsearch
    if True:  # to skip this step, set to False (e.g. resume processing after OS/HW failure)
        print("Translating reads to protein sequences")
        # file with protein consensus read sequences
        joinFastaProtGzip = os.path.join(strainsDir, '0_join_prot.fna.gz')
        fq.readsToProt(fqJoinPath, joinFastaProtGzip, comh.TRANSLATION_TABLE)

        print("Running HMMER (hmmsearch)")
        domOut = os.path.join(strainsDir, '0_join_prot.domtblout')
        joinFastaProt = joinFastaProtGzip[:-3]

        cmd = 'zcat %s > %s;%s -o /dev/null --noali --domtblout %s -E 0.01 ' \
            '--cpu %s %s %s;rm %s;gzip -f %s' % (joinFastaProtGzip, joinFastaProt, hmmsearchPath, domOut, comh.MAX_PROC,
                                                 profileHmmFile, joinFastaProt, joinFastaProt, domOut)

        assert parallel.reportFailedCmd(parallel.runCmdSerial([parallel.TaskCmd(cmd, strainsDir)])) is None

    # Assign consensus reads to individual gene domains
    if True:  # to skip this step, set to False (e.g. resume processing after OS/HW failure)
        print("Assigning consensus reads to gene domains")
        hio.partitionReads(workingDir, comh.SAMPLES_PFAM_EVAN_MIN_SCORE, comh.SAMPLES_PFAM_EVAN_MIN_ACCURACY,
                            comh.SAMPLES_SHUFFLE_RAND_SEED, comh.SAMPLES_PFAM_PARTITIONED_DIR, True, False)

    partitionedDir = os.path.join(workingDir, comh.SAMPLES_PFAM_PARTITIONED_DIR)

    # Run Assembly
    if True:  # to skip this step, set to False (e.g. resume processing after OS/HW failure)
        print("Running Snowball assembly")

        # collect tasks for each gene domain
        taskList = []
        assert os.path.isdir(partitionedDir), 'Temporary directory does not exist:\n\t%s' % partitionedDir
        for f in os.listdir(partitionedDir):
            fPath = os.path.join(partitionedDir, f)
            if f.endswith('join.fq.gz') and os.path.isfile(fPath):
                base = fPath[:-6]
                inFq = fPath
                inDomtblout = '%s_prot.domtblout.gz' % base
                inProtFna = '%s_prot.fna.gz' % base
                outPath = '%s_read_rec.pkl.gz' % base
                taskList.append(parallel.TaskThread(hmain.buildSuperReads,
                                                    (inFq, inDomtblout, inProtFna, outPath,
                                                     comh.ASSEMBLY_CONSIDER_PROT_COMP,
                                                     comh.ASSEMBLY_ONLY_POVERLAP,
                                                     comh.ASSEMBLY_POVERLAP,
                                                     comh.ASSEMBLY_OVERLAP_LEN,
                                                     comh.ASSEMBLY_OVERLAP_ANNOT_LEN,
                                                     comh.ASSEMBLY_STOP_OVERLAP_MISMATCH,
                                                     comh.ASSEMBLY_MAX_LOOPS,
                                                     comh.TRANSLATION_TABLE)))
        # run tasks in parallel
        parallel.runThreadParallel(taskList, comh.MAX_PROC, keepRetValues=False)

    # Creates the output file
    if True:  # to skip this step, set to False (e.g. resume processing after OS/HW failure)
        print('Creating output file:\n\t%s' % outFile)
        counter = 0
        out = fq.WriteFq(outFile)
        for f in os.listdir(partitionedDir):
            fPath = os.path.join(partitionedDir, f)
            if f.endswith('.pkl.gz') and os.path.isfile(fPath):
                domName = f[2:-23]
                for rec in hio.loadReadRec(fPath):
                    counter += 1
                    contigName = 'contig_%s_%s' % (counter, domName)
                    dnaSeq = rec.dnaSeq

                    # get the quality score string
                    if outAnnot or outFormat == 'fq':
                        qs = rec.qsArray.getQSStr(dnaSeq)
                    else:
                        qs = None

                    # get the contig annotations
                    if outAnnot:
                        assert qs is not None
                        codingStart = rec.annotStart
                        codingLen = rec.annotLen
                        posCov = ','.join(map(lambda x: str(int(x)), rec.getPosCovArray()))
                        annotStr = 'domName:%s|codingStart:%s|codingLen:%s|qs:%s|posCov:%s' % (domName, codingStart,
                                                                                               codingLen, qs, posCov)
                    else:
                        annotStr = ''

                    # write an entry to the output file
                    if outFormat == 'fq':
                        out.writeFqEntry('@' + contigName, dnaSeq, qs, annotStr)
                    else:
                        assert outFormat == 'fna'
                        if outAnnot:
                            annotStr = '|' + annotStr
                        out.write('>%s%s\n%s\n' % (contigName, annotStr, dnaSeq))

        # close output file
        out.close()

    # Clean up the working directory
    if cleenUpTmpWorkingDir:
        # clean up the temporary directory
        print('Cleaning up temporary directory')
        assert os.path.isdir(workingDir), 'Directory to be cleaned does not exist:\n%s' % workingDir
        shutil.rmtree(workingDir)
    elif cleanUp:
        # clean up the user defined working directory
        if os.path.isdir(workingDir):
            print('Cleaning up working directory:\n\t%s' % workingDir)
            shutil.rmtree(os.path.join(workingDir, comh.SAMPLES_PFAM_PARTITIONED_DIR))
            shutil.rmtree(strainsDir)

    print('Done')


def _main():
    """
        Main function of the master script.
    """

    # Command line parameters
    parser = argparse.ArgumentParser(
    description = 'Snowball gene assembler for Metagenomes (version 1.2).',
        epilog='This software is distributed under the GNU General Public License version 3 (http://www.gnu.org/licenses/).')

    parser.add_argument('-f', '--fq-1-file', nargs=1, type=file, required=True,
                    help='FASTQ 1 file path containing first read-ends of Illumina paired-end reads).',
                    metavar='pair1.fq.gz',
                    dest='fq1File')

    parser.add_argument('-s', '--fq-2-file', nargs=1, type=file, required=True,
                    help='FASTQ 2 file path containing second read-ends of Illumina paired-end reads).',
                    metavar='pair2.fq.gz',
                    dest='fq2File')

    parser.add_argument('-m', '--profile-hmm-file', nargs=1, type=file, required=True,
                    help='Profile HMMs file containing models of individual gene domains '
                         '(this file is generated by the HMMER 3.0 software).',
                    metavar='profile.hmm',
                    dest='profileHmmFile')

    parser.add_argument('-i', '--insert-size', nargs=1, type=int, required=True,
                    help='Mean insert size used for the library preparation (i.e. read generation).',
                    metavar='225',
                    dest='insertSize')

    parser.add_argument('-r', '--read-length', nargs=1, type=int, required=False,
                    help='Read length of the read-ends (Default: read length will be derived from the input files).',
                    metavar='150',
                    dest='readLen')

    parser.add_argument('-o', '--output-file', nargs=1, type=str, required=False,
                    help='Output FASTA or FASTQ file containing assembled contigs '
                         '(Default: the file name will be derived from the input file names).',
                    metavar='contigs.fna.gz',
                    dest='outFile')

    parser.add_argument('-t', '--output-format', nargs=1, type=str, required=False,
                    choices=['fna', 'fq'],
                    help='Format of the output file, supported: fna, fq (Default: fna).',
                    metavar='fna',
                    dest='outFormat')

    parser.add_argument('-w', '--working-directory', nargs=1, type=str, required=False,
                    help='Working directory (Default: a temporary working directory will be automatically '
                         'created and removed).',
                    metavar='wd',
                    dest='workingDir')

    parser.add_argument('-e', '--hmmsearch-path', nargs=1, type=file, required=False,
                    help='Path to the HMMER hmmsearch command (Default: the version in the PATH will be used).',
                    metavar='/usr/bin/hmmsearch',
                    dest='hmmsearchPath')

    parser.add_argument('-n', '--hmmsearch-min-score', nargs=1, type=int, required=False,
                    help='Minimum score for the reads to gene domains assignments (Default: 40).',
                    metavar='40',
                    dest='pfamMinScore')

    parser.add_argument('-v', '--minimum-overlap-probability', nargs=1, type=float, required=False,
                    help='Minimum overlap probability parameter of the Snowball algorithm (Default: 0.8).',
                    metavar='0.8',
                    dest='pOverlap')

    parser.add_argument('-l', '--min-overlap-length', nargs=1, type=float, required=False,
                    help='Minimum overlap length parameter of the Snowball algorithm (Default: 0.5).',
                    metavar='0.5',
                    dest='overlapLen')

    parser.add_argument('-a', '--output-contig-annotation', action='store_true', required=False,
                    help='Store additional contig annotation along with the contigs.'
                         ' (Default: no annotation is stored).',
                    dest='outAnnot')

    parser.add_argument('-c', '--clean-up', action='store_true', required=False,
                    help='Clean up the working directory. If a temporary working directory is automatically created, '
                         'it will always be cleaned up. (Default: no clean up is performed).',
                    dest='cleanUp')

    parser.add_argument('-p', '--processors', nargs=1, type=int, required=False,
                    help='Number of processors to be used (Default: all available processors will be used).',
                    metavar='60',
                    dest='processors')

    args = parser.parse_args()

    # Values that must be defined
    fq1File = None
    fq2File = None
    profileHmmFile = None
    insertSize = None

    # Default values
    outFormat = 'fna'
    pfamMinScore = 40
    pOverlap = 0.8
    overlapLen = 0.5
    outAnnot = False
    cleanUp = False
    processors = mp.cpu_count()
    readLen = None
    outFile = None
    workingDir = None
    hmmsearchPath = None

    # reading arguments
    if args.fq1File:
        fq1File = normPath(args.fq1File[0].name)

    if args.fq2File:
        fq2File = normPath(args.fq2File[0].name)

    if args.profileHmmFile:
        profileHmmFile = normPath(args.profileHmmFile[0].name)

    if args.insertSize:
        insertSize = int(args.insertSize[0])

    if args.readLen:
        readLen = int(args.readLen[0])

    if args.outFile:
        outFile = normPath(args.outFile[0])

    if args.outFormat:
        outFormat = args.outFormat[0]

    if args.workingDir:
        workingDir = normPath(args.workingDir[0])

    if args.hmmsearchPath:
        hmmsearchPath = normPath(args.hmmsearchPath[0].name)

    if args.pfamMinScore:
        pfamMinScore = int(args.pfamMinScore[0])

    if args.pOverlap:
        pOverlap = float(args.pOverlap[0])

    if args.overlapLen:
        overlapLen = float(args.overlapLen[0])

    if args.outAnnot:
        outAnnot = args.outAnnot

    if args.cleanUp:
        cleanUp = args.cleanUp

    if args.processors:
        processors = int(args.processors[0])

    # Printing for debugging.
    if False:  # set to True to print input parameters
        print('fq1File: %s' % fq1File)
        print('fq2File: %s' % fq2File)
        print('profileHmmFile: %s' % profileHmmFile)
        print('insertSize: %s' % insertSize)
        print('readLen: %s' % readLen)
        print('outFile: %s' % outFile)
        print('outFormat: %s' % outFormat)
        print('workingDir: %s' % workingDir)
        print('hmmsearchPath: %s' % hmmsearchPath)
        print('pfamMinScore: %s' % pfamMinScore)
        print('pOverlap: %s' % pOverlap)
        print('overlapLen: %s' % overlapLen)
        print('outAnnot: %s' % outAnnot)
        print('cleanUp: %s' % cleanUp)
        print('processors: %s' % processors)

    # Run Snowball
    mainSnowball(fq1File, fq2File, profileHmmFile, insertSize,
                 readLen=readLen, outFile=outFile, outFormat=outFormat, workingDir=workingDir,
                 hmmsearchPath=hmmsearchPath, pfamMinScore=pfamMinScore, pOverlap=pOverlap, overlapLen=overlapLen,
                 outAnnot=outAnnot, cleanUp=cleanUp, processors=processors)


def normPath(path):
    if os.path.isabs(path) or path.strip().startswith('~'):
        return path
    else:
        return os.path.abspath(path)

# TESTS ---------------------------------------------------

def _test():
    fq1File = '/home/igregor/Documents/work/release_snow/input/10_1_NZ_AIGN00000000_p1.fq.gz'
    fq2File = '/home/igregor/Documents/work/release_snow/input/10_1_NZ_AIGN00000000_p2.fq.gz'
    profileHmmFile = '/home/igregor/Documents/work/db/pfamV27/Pfam-A_and_Amphora2.hmm'
    insertSize = 225
    outFile = '/home/igregor/Documents/work/release_snow/out.fna'
    outFormat = 'fna'  # or 'fq'
    workingDir = '/home/igregor/Documents/work/release_snow/working'
    hmmsearchPath = '/home/igregor/Documents/work/tools/hmmer-3.0/binaries/hmmsearch'
    mainSnowball(fq1File, fq2File, profileHmmFile, insertSize, readLen=None, outFile=outFile, outFormat=outFormat,
                 workingDir=workingDir, hmmsearchPath=hmmsearchPath, pfamMinScore=None, outAnnot=False, cleanUp=False,
                 processors=mp.cpu_count())

if __name__ == "__main__":
    _main()
    # _test()
